{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!git clone https://github.com/dionis/multimodal_rag_ai.git",
   "id": "9df3ae85625de219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cd multimodal_rag_ai",
   "id": "83a81d74400a2d4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!git checkout develop",
   "id": "82d4adaecb87faea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip uninstall protobuf==4.25.5",
   "id": "a4d62a7d38220f80"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T23:23:24.105758Z",
     "start_time": "2024-09-20T23:23:19.916504Z"
    }
   },
   "source": "!pip install -r requirements.txt",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '../requirements.txt'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Available pyngrok for https localhost\n",
    "\n",
    "- Bibliografy: [Run localhost server in Google Colab notebook](https://stackoverflow.com/questions/60571301/run-localhost-server-in-google-colab-notebook)\n"
   ],
   "id": "136dde36c87cc3a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install pyngrok --quiet",
   "id": "2a5625617634d436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Terminate open tunnels if exist\n",
    "ngrok.kill()\n",
    "\n",
    "# Setting the authtoken (optional)\n",
    "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
    "NGROK_AUTH_TOKEN = \"\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
    "PUBLIC_URL = ngrok.connect(port=\"8079\", proto=\"https\", options={\"bind_tls\": True})\n",
    "print(\"Tracking URL:\", PUBLIC_URL)"
   ],
   "id": "9d48472f16459c6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "import weaviate, os\n",
    "\n",
    "#############################################################\n",
    "#\n",
    "#  Bibliography:\n",
    "#    Gradio theme https://huggingface.co/spaces/gradio/theme-gallery\n",
    "#\n",
    "#    Gradio Tutorial:\n",
    "#         https://www.youtube.com/watch?v=ABNxNFPqIGQ&t=4s\n",
    "#         https://www.youtube.com/watch?v=44vi31hehw4\n",
    "#\n",
    "#   DeepLearning.AI (https://learn.deeplearning.ai/courses/building-multimodal-search-and-rag/lesson/1/introduction)\n",
    "#   platform course: Building Multimodal Search and RAG\n",
    "###############################################################\n",
    "\n",
    "import os\n",
    "\n",
    "from click import prompt\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import textwrap\n",
    "import PIL.Image\n",
    "import google.generativeai as genai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.colab import userdata"
   ],
   "id": "804820a43eca073d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### *Load gemmini (LLM) client*",
   "id": "ba12227fe37e95f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_ = load_dotenv(find_dotenv('../config/.env')) # read local .env file\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') if GOOGLE_API_KEY == None else GOOGLE_API_KEY\n",
    "\n",
    "print(f\"The Gemmi API KEY found is {GOOGLE_API_KEY}\")\n",
    "#Configure API KEY GEMMINI\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ],
   "id": "8c796e4c147c1d63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "SYSTEM_PROMPT_IDENTIFIED = \"Explain what you see in this image.\""
   ],
   "id": "33f6fca644d089a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### *Functions for call LLM request*",
   "id": "57f8caad80d37366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def to_markdown(text):\n",
    "    text = text.replace('â€¢', '  *')\n",
    "    return textwrap.indent(text, '> ', predicate=lambda _: True)\n",
    "\n",
    "\n",
    "def call_Gemmi_LLM(image_path: str, prompt: str) -> str:\n",
    "    # Load the image\n",
    "    # img = PIL.Image.open(image_path)\n",
    "\n",
    "    sample_file = genai.upload_file(path=image_path, display_name=\"Sample drawing\")\n",
    "\n",
    "    #\n",
    "    # Call generative model\n",
    "    #\n",
    "    #\n",
    "\n",
    "    model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
    "\n",
    "    response = model.generate_content(\n",
    "        [prompt, sample_file]\n",
    "    )\n",
    "\n",
    "    return to_markdown(response.text)\n",
    "\n",
    "def inference(prompt, inp_img, inp_video, token):\n",
    "    time.sleep(3)\n",
    "    result_call_video_gemmini = result_call_image_gemmini = ''\n",
    "    prompt = SYSTEM_PROMPT_IDENTIFIED\n",
    "\n",
    "    if inp_img != '' and inp_img is not None:\n",
    "      result_call_image_gemmini = call_Gemmi_LLM(inp_img, prompt)\n",
    "\n",
    "    if inp_video != '' and inp_video is not None:\n",
    "        print(f\"Video Address to show and index ${inp_video}\")\n",
    "        result_call_video_gemmini = call_Gemmi_LLM(inp_video, prompt)\n",
    "\n",
    "    return [f\" Prompt {prompt} \\n\\n Image:\\n {result_call_image_gemmini},\\n\\n\\n Video:\\n {result_call_video_gemmini}\",\"B\"]\n",
    "\n",
    "def multimodalraginference(*args):\n",
    "    gr.Warning(\"Building action!!!!\")\n",
    "    return\n",
    "\n",
    "def multimodalrecomendation(*args):\n",
    "    gr.Warning(\"Building action!!!!\")\n",
    "    return"
   ],
   "id": "8847e96a320048bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weviate client request",
   "id": "3078aed12ee0ca32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EMBEDDING_API_KEY = os.getenv(\"WEVIATE_API_ADMIN_KEY\")\n",
    "\n",
    "EMBEDDING_API_KEY = userdata.get('WEVIATE_API_ADMIN_KEY') if EMBEDDING_API_KEY == None else EMBEDDING_API_KEY\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.24.21\",\n",
    "    environment_variables={\n",
    "        \"ENABLE_MODULES\": \"backup-filesystem,multi2vec-palm\",\n",
    "        \"BACKUP_FILESYSTEM_PATH\": \"../backups\",\n",
    "    },\n",
    "    headers={\n",
    "        \"X-PALM-Api-Key\": EMBEDDING_API_KEY,\n",
    "    },\n",
    "    hostname = PUBLIC_URL\n",
    ")\n",
    "\n",
    "client.is_ready()"
   ],
   "id": "c248e776947b62a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create gradio UI",
   "id": "1f429951bc6ffab1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#########################################\n",
    "#\n",
    "#   Bibliografy:\n",
    "#     Google AI Generative AI with Weaviate (https://weaviate.io/developers/weaviate/model-providers/google/generative)\n",
    "#\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "\n",
    "with gr.Blocks(theme = 'JohnSmith9982/small_and_pretty') as demo:\n",
    "    with gr.Tab(\"Multimodal Search \"):\n",
    "        message = (\"### Use LLM Multimodal Prompt search with Gradio using these \\\n",
    "        [video tutorial](https://www.youtube.com/watch?v=ABNxNFPqIGQ&t=4s) and Hugging Face API\")\n",
    "        gr.Markdown(\"<center><h2>Open LLM Explorer</h2></center>\")\n",
    "        gr.Markdown(message)\n",
    "\n",
    "        prompt = gr.Textbox(label = 'Prompt', lines= 3, max_lines = 5, value = SYSTEM_PROMPT_IDENTIFIED)\n",
    "        with gr.Row():\n",
    "            # Image gradio component bibliography https://www.gradio.app/docs/gradio/image\n",
    "            #\n",
    "            inp_img = gr.Image(label=\"Image to Search\",type=\"filepath\")\n",
    "\n",
    "            # Video gradio component bibliography https://www.gradio.app/docs/gradio/video\n",
    "            #\n",
    "            #\n",
    "            inp_video = gr.Video(label=\"Video to Search\")\n",
    "        token = gr.Textbox(label='Token', type='password')\n",
    "\n",
    "\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                generate_btn = gr.Button(\"Generate\", size = \"lg\", variant = \"primary\")\n",
    "                code_btn = gr.Button(\"View Code\", size = \"lg\", variant = \"secondary\")\n",
    "\n",
    "        with gr.Row() as row_output:\n",
    "           llama_output = gr.Markdown(\"##Llama3.1 70B-instruct Output\")\n",
    "           groq_output = gr.Markdown(\"##Groq with Llama3.1 70B-instruct Output\")\n",
    "\n",
    "        generate_btn.click(fn= inference, inputs=[prompt, inp_img, inp_video, token],outputs=[llama_output,groq_output])\n",
    "    with gr.Tab(\"RAG Multimodal\"):\n",
    "        ragMultimodal_button = gr.Button(\"In Building\")\n",
    "\n",
    "        ragMultimodal_button.click(fn = multimodalraginference)\n",
    "    with gr.Tab(\"Multimodal Recommendation\"):\n",
    "        ragMultimodal_button = gr.Button(\"In Building\")\n",
    "\n",
    "        ragMultimodal_button.click(fn = multimodalrecomendation)\n",
    "\n",
    "\n",
    "demo.launch()\n"
   ],
   "id": "d2788d7cbe61c01d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
